---
title: "Final_Assignment"
author: "Brecht Van Buggenhout"
date: "12/14/2022"
output: html_document
---

```{r}
# Loading the library
library(class)
library(ggplot2)
library(mvtnorm)
library(pROC)
library(MASS)
library(tree)
library(psych)
library(rpart)
library(randomForest)
library(gbm)
library(xgboost)
library(caret)
library(plyr)
library(dplyr)
library(Hmisc)
library(corrplot)
library(ROCR)
library(rpart)
```

Data cleaning - same for every model

```{r}
# clear the environment
rm(list = ls())

# read in csv file and aprropriate libraries
library(Hmisc)
dat_train <- read.table("train.csv", sep=",", header=TRUE)
dat_test <- read.csv("test.csv")
gender <- read.csv("gender_submission.csv")
dim(dat_train)
describe(dat_train)[,1:12]
describe(dat_test)[,1:11]
head(dat_train)
dat_test <- merge(dat_test,gender, by = "PassengerId")

# get rid of columns that are not useful to predictions
# name, passengerid, ticket, and cabin
dat_train_fin <- dat_train[,-c(1,4,9,11)]
dat_test_fin <- dat_test[,-c(1,3,8,10)]

# get rid of null values
df1_train <- na.omit(dat_train_fin)
describe(df1_train)
describe(dat_test_fin)

# convert sex to binary values
df1_train$Sex <- ifelse(df1_train$Sex=="male",1,0)
dat_test_fin$Sex <- ifelse(dat_test_fin$Sex=="male",1,0)
dat_test_fin$Age <- ifelse(is.na(dat_test_fin$Age) == TRUE, 30.27, dat_test_fin$Age)
dat_test_fin$Fare <- ifelse(is.na(dat_test_fin$Fare) == TRUE, 35.63, dat_test_fin$Fare)

# removing rows without any embarked port
df1_train <- df1_train[!df1_train$Embarked == "",]

# converting embarked to factor
df1_train$Embarked <- as.factor(df1_train$Embarked)
```

Data exploration

```{r}
# how many people died versus how many people survived
table(df1_train$Survived)
library(ggplot2)

# histogram to show distribution of age
ggplot(df1_train, aes(x = Age)) +
  geom_histogram(breaks = seq(0,80, by = 5)) 
labs(x = "Age") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

# histogram of fare --> using log
ggplot(df1_train, aes(x = Fare)) +
  geom_histogram(breaks = seq(0,10, by = 1)) 
labs(x = "Fare") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

df1_train %>%
  group_by(Embarked) %>%
  summarise(
    zeros = sum(Survived == 0),
    ones = sum(Survived == 1),
    n = n(),
    proportion = mean(Survived)
  )
```
```{r}
# Split the training data into train_train and train_validation
set.seed(42)
trn <- runif(nrow(df1_train)) < .7
df1_train_train <- df1_train[trn,]
df1_train_validation <- df1_train[trn==FALSE,]
```

Neural nets --> neural net 1 performed the best

```{r}

# create formula
form1 <- formula(df1_train_train$Survived~.)

# We commence with a good combination from prior studies
# maximal iterations of 100, and a decay= of 0.0001.
library(nnet)
n1 <- nnet(form1, data=df1_train_train, size=3, maxit=500, decay=0.001)

# lets check predictions
yhat.n1 <- predict(n1, df1_train_validation)

#create confusion matrix
table(yhat.n1[,1]>0.625, df1_train_validation$Survived)

# check the ROC curve and AUC
library("pROC")
n1.roc <- roc(df1_train_validation$Survived, yhat.n1[,1], direction="<")
n1.roc
plot(n1.roc, lwd=3)

# create dataset to show results of first predictions
yhat.n1.test <- predict(n1, dat_test_fin)
yhat.n1.test <- ifelse(yhat.n1.test[,1] >0.625,1,0)
df <- data.frame(yhat.n1.test)
names(df) <- c('Survived')
df$PassengerId <- c(892:1309)
write.csv(df, "Survived.csv", row.names=FALSE)

# neural net 2
n2 <- nnet(form1, data=df1_train_train, size=10, maxit=200, decay=0.001)
yhat.n2 <- predict(n2, df1_train_validation)
table(yhat.n2[,1]>0.625, df1_train_validation$Survived)
n2.roc <- roc(df1_train_validation$Survived, yhat.n2[,1], direction="<")
n2.roc
plot(n2.roc, add = TRUE, col="blue")

# create dataset fro 2nd neural net
yhat.n2.test <- predict(n2, dat_test_fin)
yhat.n2.test <- ifelse(yhat.n2.test[,1] >0.625,1,0)
df2 <- data.frame(yhat.n2.test)
names(df2) <- c('Survived')
df2$PassengerId <- c(892:1309)
write.csv(df2, "Survived2.csv", row.names=FALSE)

# neural net 3
n3 <- nnet(form1, data=df1_train_train, size=10, maxit=500, decay=0.001)
yhat.n3 <- predict(n3, df1_train_validation)
table(yhat.n3[,1]>0.625, df1_train_validation$Survived)
n3.roc <- roc(df1_train_validation$Survived, yhat.n3[,1], direction="<")
n3.roc
plot(n3.roc, add = TRUE, col="red")

# create dataset fro 3rd neural net
yhat.n3.test <- predict(n3, dat_test_fin)
yhat.n3.test <- ifelse(yhat.n3.test[,1] >0.625,1,0)
df3 <- data.frame(yhat.n3.test)
names(df3) <- c('Survived')
df3$PassengerId <- c(892:1309)
write.csv(df3, "Survived3.csv", row.names=FALSE)

# lets use more iterations for neural net 4
n4 <- nnet(form1, data=df1_train_train, size=5, maxit=1000, decay=0.0001)
yhat.n4 <- predict(n4, df1_train_validation)
table(yhat.n4[,1]>0.625, df1_train_validation$Survived)
n4.roc <- roc(df1_train_validation$Survived, yhat.n4[,1], direction="<")
n4.roc
plot(n4.roc, add = TRUE, col="green")

# create dataset fro 4th neural net
yhat.n4.test <- predict(n4, dat_test_fin)
yhat.n4.test <- ifelse(yhat.n4.test[,1] >0.625,1,0)
df4 <- data.frame(yhat.n4.test)
names(df4) <- c('Survived')
df4$PassengerId <- c(892:1309)
write.csv(df4, "Survived4.csv", row.names=FALSE)

# compare nets
temp <- data.frame(yhat.n1[,1],yhat.n2[,1],yhat.n3[,1],yhat.n4[,1],df1_train_validation$Survived)
rho <- cor(temp)
corrplot(rho, method="number")
```

Classification tree --> did better than 2 worst neural nets, but worse than best 2 neural nets
```{r}

# Split the training data into train_train and train_validation
set.seed(42)
trn <- runif(nrow(df1_train)) < .7
df1_train_train <- df1_train[trn,]
df1_train_validation <- df1_train[trn==FALSE,]

form1 <- formula(Survived~.)
t1 <- rpart(form1, data=df1_train_train, cp=.001, method="class")
plot(t1,uniform=T,compress=T,margin=.05,branch=0.3)
text(t1, cex=.7, col="navy",use.n=TRUE)

# make predictions on first tree
yhat.t1 <- predict(t1, df1_train_validation, type="prob")[,2]
table(yhat.t1>0.625,df1_train_validation$Survived)

# plotting the t1
plotcp(t1)

# 
CP <- printcp(t1)

# the left variable is a good choice for pruning if below the line in classification trees
cp <- CP[,1][CP[,2]==2]
cp

# prune according to cp calculate above
t2 <- prune(t1,cp=cp[1])
plot(t2,uniform=T,compress=T,margin=.05,branch=0.3)
text(t2, cex=.7, col="navy",use.n=TRUE)

# make predictions based on tree 2
yhat.t2 <- predict(t2, df1_train_validation, type="prob")[,2]
table(yhat.t2>0.625,df1_train_validation$Survived)

# make predictions based on tree 1
yhat.t1 <- predict(t1, df1_train_validation, type="prob")[,2]
table(yhat.t1>0.625,df1_train_validation$Survived)

# plotting the ROC curve and calculating the AUC
t1.roc <- roc(df1_train_validation$Survived, yhat.t1, direction="<")
t1.roc
plot(t1.roc, lwd=3)

# plotting the ROC curve and calculating the AUC
t2.roc <- roc(df1_train_validation$Survived, yhat.t2, direction="<")
t2.roc
plot(t2.roc, lwd=3)

# create dataset to show results of first predictions
yhat.t1.test <- predict(t1, dat_test_fin)
yhat.t1.test <- ifelse(yhat.t1.test[,1] >0.625,1,0)
df <- data.frame(yhat.t1.test)
names(df) <- c('Survived')
df$PassengerId <- c(892:1309)
write.csv(df, "Survived_classtree.csv", row.names=FALSE)
df

# create dataset to show results of first predictions
yhat.t2.test <- predict(t2, dat_test_fin)
yhat.t2.test <- ifelse(yhat.t2.test[,1] >0.625,1,0)
df <- data.frame(yhat.t2.test)
names(df) <- c('Survived')
df$PassengerId <- c(892:1309)
write.csv(df, "Survived_classtreeprune.csv", row.names=FALSE)
df

```

Random Forest --> did better than class tree but worse than best neural nets
```{r}


# Setting up the random forest
library(xgboost)
library(randomForest)


X <- as.matrix(df1_train_train[,-c(1,8)])
Y <- df1_train_train$Survived
dim(X)

mtry <- round(ncol(X)^0.5); mtry
# Fitting random forest to the dataset
ntree <- 1000
set.seed(652)
rf1 <- randomForest(x=X, y=Y, ntree=ntree, mtry=mtry, importance=TRUE)
rf1

# summary of the random forest
summary(rf1)
names(rf1)


# look at "importance' since it gives us the influence of each feature
importance(rf1)

# look at the rf1 in a plot setting
varImpPlot(rf1)

# evaluating predictions
yhat.rf1 <- predict(rf1, df1_train_validation)
table(yhat.rf1>0.625,df1_train_validation$Survived)


# let's look at the ROC curve and AUC
library(pROC)
rf1.roc <- roc(df1_train_validation$Survived, yhat.rf1, direction="<")
rf1.roc
plot(rf1.roc, lwd=3)

# create dataset to show results of first predictions
yhat.rf1.test <- predict(rf1, dat_test_fin)
yhat.rf1.test <- ifelse(yhat.rf1.test >0.625,1,0)
df <- data.frame(yhat.rf1.test)
names(df) <- c('Survived')
df$PassengerId <- c(892:1309)
write.csv(df, "Survived_rndmforest.csv", row.names=FALSE)
df
```

GLM --> slightly worse than class tree - worst in total
```{r}

# remove 0 value for fare in train data
df1_train <- df1_train[df1_train$Fare > 0,] #7 observations removed

# convert sex to binary values
df1_train$Fare <- log(df1_train$Fare)
dat_test_fin$Fare <- log(dat_test_fin$Fare)

trn <- runif(nrow(df1_train)) < .7
df1_train_train <- df1_train[trn,]
df1_train_validation <- df1_train[trn==FALSE,]


# run glm
glm <- glm(Survived ~., family = "binomial", data = df1_train_train)
summary(glm)

# predictions of this glm
yhat1 <- predict(glm, df1_train_validation, type = "response")
test.glm <- rep(0,length(dat_test_fin[,1]))
test.glm[yhat1 > 0.625] <- 1
table(test.glm, dat_test_fin$Survived)


# AUC and ROC
g1.roc <- roc(df1_train_validation$Survived, yhat1, direction="<")
g1.roc
plot(g1.roc, lwd=3)

# create dataset to show results of first predictions
yhat.glm.test <- predict(glm, dat_test_fin)
yhat.glm.test <- ifelse(yhat.glm.test >0.625,1,0)
df <- data.frame(yhat.glm.test)
names(df) <- c('Survived')
df$PassengerId <- c(892:1309)
write.csv(df, "Survived_glm.csv", row.names=FALSE)
df
```
